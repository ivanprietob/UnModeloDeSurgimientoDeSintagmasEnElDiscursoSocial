{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formación de sintagmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*********************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables:\n",
    "\n",
    "$w=[w_1, ..., w_n] \\rightarrow$ El sintagma\n",
    "\n",
    "* $e_t \\in \\{0,1\\} \\rightarrow$ Ocurrencia del evento en el momento $t$\n",
    "* $s_t \\in \\{0,1\\} \\rightarrow$ Existencia de la situación en el momento $t$\n",
    "* $s_{t-1} \\rightarrow$ Situación en el momento $t-1$\n",
    "* $w_t^i \\rightarrow$ El evento del sintagma siendo formado en el momento $t$:\n",
    "    * $i=0$: hipótesis de que el sintagma no se ha formado aún\n",
    "    * $i=1$: hipótesis de que el sintagma se ha formado\n",
    "* $\\pi_t \\rightarrow$ Observación\n",
    "\n",
    "\\begin{matrix}\n",
    "    \\pi^1 = \\left\\{\n",
    "        \\begin{matrix} \n",
    "            \\frac{n(w_1...w_n)}{max(n(w_1), ..., n(w_n))} & if\\ \\max(n(w_1), ..., n(w_n)) > 0\n",
    "                \\\\\n",
    "            0 & otherwise \n",
    "        \\end{matrix}\\right.\n",
    "    \\\\\n",
    "    \\pi^0=1-\\pi^1\n",
    "\\end{matrix}\n",
    "\n",
    "**La calidad *q* del sintagma no se va a tener en cuenta**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*********************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $\\alpha_j^i(t)=P[w_t=i|s_t=j]$\n",
    "\n",
    "* $\\beta_{kh}^j(t)=P[s_t=j|s_{t-1}=k,e_t=h]$\n",
    "\n",
    "* $\\nu^k(t)=P[s_{t-1}=k]$\n",
    "\n",
    "* $\\gamma^h(t)=P[e_t=h]$\n",
    "\n",
    "* $\\tau_i^{jkh}=P(s_t=j,s_{t-1}=k, e_t=h|w=i)$\n",
    "\n",
    "$i, j, k, h \\in \\{0,1\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*********************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = list()\n",
    "months = list()\n",
    "\n",
    "years.extend(LAST_DECADE)\n",
    "months.extend(ALL_MONTHS)\n",
    "\n",
    "syntagm = \"lock down\"\n",
    "\n",
    "count_individual_words = dict()\n",
    "split = syntagm.split(\" \")\n",
    "\n",
    "for year in years:\n",
    "    for month in months:\n",
    "\n",
    "        count_syntagm = 0\n",
    "\n",
    "        for word in split:\n",
    "            count_individual_words[word] = 0\n",
    "\n",
    "        path = DATA_PATH + str(year) + \"/\" + str(month) + EXT\n",
    "\n",
    "        with open(path, \"r\") as f:\n",
    "\n",
    "            docs = json.loads(f.read())[DATA]\n",
    "\n",
    "            for i, doc in enumerate(docs):\n",
    "\n",
    "                abstract = doc[ABSTRACT]\n",
    "                snippet = doc[SNIPPET]\n",
    "                lead = doc[LEAD_PAR]\n",
    "\n",
    "                count_syntagm += abstract.count(syntagm) + \\\n",
    "                    snippet.count(syntagm) + lead.count(syntagm)\n",
    "\n",
    "                for word in count_individual_words:\n",
    "                    regex = fr\"\\b{word}\\b\"\n",
    "\n",
    "                    num_abstract = len(re.findall(regex, abstract, re.IGNORECASE))\n",
    "                    num_snippet = len(re.findall(regex, snippet, re.IGNORECASE))\n",
    "                    num_lead = len(re.findall(regex, lead, re.IGNORECASE))\n",
    "\n",
    "                    count_individual_words[word] += num_abstract + num_snippet + num_lead\n",
    "\n",
    "\n",
    "        if count_syntagm != 0:\n",
    "            print(f\"Numero de veces que aparece el sintagma entero'{syntagm}' en {year}/{month} --> {count_syntagm}\", end=\"\")\n",
    "        print(f\"\\t {count_individual_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideraciones previas:\n",
    "\n",
    "- La situación no se ha dado en $t=0$\n",
    "    - $\\nu^0(t)=1$\n",
    "    - $\\nu^1(t)=0$\n",
    "\n",
    "- $\\psi$: lista que, para cada t, contiene la probabilidad de que el evento que causa el sintagma se genere\n",
    "\n",
    "- $\\alpha, \\beta, \\nu, \\gamma$ son listas de:\n",
    "\n",
    "    - n listas, siendo n el subíndice:\n",
    "        - cada lista de m posiciones según el superíndice.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- $\\alpha$: [[ , ], [ , ]]\n",
    "- $\\beta$: [[ [ , ] , [ , ] ], [ [ , ] , [ , ] ]]\n",
    "- $\\nu$: una lista de dos posiciones\n",
    "- $\\gamma$: una lista de dos posiciones\n",
    "\n",
    "- $\\tau$: ocho listas de dos posiciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "EXT = \".json\"\n",
    "\n",
    "ALL_MONTHS = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "LAST_DECADE = [2019, 2020, 2021, 2022, 2023]\n",
    "\n",
    "DATA_PATH = \"data/\"\n",
    "\n",
    "RESPONSE = \"response\"\n",
    "DOCS = \"docs\"\n",
    "DATA = \"data\"\n",
    "\n",
    "ABSTRACT = \"abstract\"\n",
    "SNIPPET = \"snippet\"\n",
    "LEAD_PAR = \"lead_paragraph\"\n",
    "PUB_DATE = \"pub_date\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pi(year, month, syntagm):\n",
    "\n",
    "    # contador para las apariciones del sintagma completo\n",
    "    count_syntagm = 0\n",
    "\n",
    "    # diccionario contador para las apariciones de cada una de las palabras\n",
    "    split = syntagm.split(\" \")\n",
    "    count_individual_words = dict()\n",
    "    \n",
    "    if len(split) > 1:\n",
    "        for word in split:\n",
    "            count_individual_words[word] = 0\n",
    "\n",
    "    # ruta al json de datos\n",
    "    path = DATA_PATH + str(year) + \"/\" + str(month) + EXT\n",
    "\n",
    "    with open(path, \"r\") as f:\n",
    "\n",
    "        # cargamos el json en memoria\n",
    "        docs = json.loads(f.read())[DATA]\n",
    "\n",
    "        for doc in docs:\n",
    "\n",
    "            abstract = doc[ABSTRACT]\n",
    "            snippet = doc[SNIPPET]\n",
    "            lead = doc[LEAD_PAR]\n",
    "\n",
    "            # contamos el numero de apariciones del sintagma completo\n",
    "            count_syntagm += abstract.count(syntagm) + snippet.count(syntagm) + lead.count(syntagm)\n",
    "\n",
    "            if len(split) > 1:\n",
    "\n",
    "                # contamos el numero de apariciones de cada termino del sintagma\n",
    "                # mediante una expresion regular\n",
    "                for word in count_individual_words:\n",
    "                    regex = fr\"\\b{word}\\b\"\n",
    "\n",
    "                    num_abstract = len(re.findall(regex, abstract, re.IGNORECASE))\n",
    "                    num_snippet = len(re.findall(regex, snippet, re.IGNORECASE))\n",
    "                    num_lead = len(re.findall(regex, lead, re.IGNORECASE))\n",
    "\n",
    "                    count_individual_words[word] += num_abstract + num_snippet + num_lead\n",
    "\n",
    "    if len(split) > 1:\n",
    "        return [count_syntagm, max(count_individual_words.values())]\n",
    "    else:\n",
    "        return [count_syntagm, count_syntagm]\n",
    "\n",
    "\n",
    "syntagm = \"lockdown\"\n",
    "\n",
    "for i in range(2014, 2021):\n",
    "    print(i)\n",
    "    for j in range(1, 13):\n",
    "        pi = compute_pi(i, j, syntagm)\n",
    "        print(\"\\t\", pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gamma:\n",
      "\n",
      " [0.91469927 0.87601722]\n",
      "\n",
      "--> pi:\n",
      "\n",
      " [0.46009079 0.53990921]\n",
      "[1 0]\n",
      "\n",
      "------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "beta = np.random.rand(2, 2, 2)\n",
    "# print(\"\\nbeta:\")\n",
    "# print(\"\\n\", beta)\n",
    "\n",
    "gamma = np.random.rand(2)\n",
    "print(\"\\ngamma:\")\n",
    "print(\"\\n\", gamma)\n",
    "\n",
    "pi = np.random.dirichlet(np.ones(2))\n",
    "print(\"\\n--> pi:\")\n",
    "print(\"\\n\", pi)\n",
    "\n",
    "tau = np.random.rand(2, 2, 2, 2)\n",
    "# print(\"\\ntau:\")\n",
    "# print(\"\\n\", tau)\n",
    "\n",
    "alpha = np.random.rand(2, 2)\n",
    "# print(\"\\n--> alpha:\")\n",
    "# print(\"\\n\", alpha)\n",
    "\n",
    "nu = np.array([1, 0])\n",
    "print(nu)\n",
    "\n",
    "print(\"\\n------------------------------------------\\n\")\n",
    "\n",
    "\n",
    "def compute_alpha(alpha, tau):\n",
    "\n",
    "    for i, level_zero in enumerate(alpha):\n",
    "        for j, _ in enumerate(level_zero):\n",
    "\n",
    "            numerador = pi[i] * tau[i][j].sum()\n",
    "\n",
    "            alpha[i][j] = numerador\n",
    "\n",
    "    return alpha\n",
    "\n",
    "\n",
    "def compute_beta(beta, tau):\n",
    "\n",
    "    for i, level_zero in enumerate(beta):\n",
    "        for j, level_one in enumerate(level_zero):\n",
    "            for k, _ in enumerate(level_one):\n",
    "\n",
    "                numerador = 0\n",
    "                for h, _ in enumerate(pi):\n",
    "                    numerador += pi[h] * tau[i][j][k][h]\n",
    "\n",
    "                beta[i][j][k] = numerador\n",
    "\n",
    "    return beta\n",
    "\n",
    "\n",
    "def compute_gamma(gamma, tau):\n",
    "\n",
    "    for i, _ in enumerate(gamma):\n",
    "\n",
    "        numerador = 0\n",
    "        for j, level_one in enumerate(tau):\n",
    "            for k, level_two in enumerate(level_one):\n",
    "                for h, _ in enumerate(level_two):\n",
    "                    numerador += pi[j] * tau[i][j][k][h]\n",
    "\n",
    "        gamma[i] = numerador\n",
    "\n",
    "    return gamma\n",
    "\n",
    "\n",
    "def compute_tau(tau, alpha, beta, nu, gamma, t):\n",
    "\n",
    "    for i, level_zero in enumerate(tau):\n",
    "        for j, level_one in enumerate(level_zero):\n",
    "            for k, level_two in enumerate(level_one):\n",
    "                for h, _ in enumerate(level_two):\n",
    "\n",
    "                    numerador = alpha[i][j] * beta[j][k][h] * \\\n",
    "                        nu[k] * (t - 1) * gamma[h]\n",
    "                    tau[i][j][k][h] = numerador\n",
    "    return tau\n",
    "\n",
    "\n",
    "times = 10\n",
    "for t in range(2, times):\n",
    "\n",
    "    tau = compute_tau(tau, alpha, beta, nu, gamma, t)\n",
    "    alpha = compute_alpha(alpha, tau)\n",
    "    beta = compute_beta(beta, tau)\n",
    "    gamma = compute_gamma(gamma, tau)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
